{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d05b3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import torch\n",
    "\n",
    "import sys \n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pipeline_attend_and_excite import AttendAndExcitePipeline\n",
    "from config import RunConfig\n",
    "from run import run_on_prompt, get_indices_to_alter\n",
    "import vis_utils\n",
    "from ptp_utils import AttentionStore\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b7a0d",
   "metadata": {},
   "source": [
    "## Load Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5e89178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't connect to the Hub: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/stabilityai/stable-diffusion-2-1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f349282c710>, 'Connection to huggingface.co timed out. (connect timeout=None)'))\"), '(Request ID: 27b80b71-b21b-4db4-99ce-8deff3f7b9c5)').\n",
      "Will try to load from local cache.\n",
      "Loading pipeline components...:  33%|███▎      | 2/6 [00:00<00:00, 24.52it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import diffusers.schedulers.scheduling_ddpm because of the following error (look up to see its traceback):\ncannot import name 'randn_tensor' from 'diffusers.utils' (/root/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/utils/import_utils.py:883\u001b[39m, in \u001b[36m_get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:999\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/schedulers/scheduling_ddpm.py:25\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfigMixin, register_to_config\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseOutput, randn_tensor\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscheduling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KarrasDiffusionSchedulers, SchedulerMixin\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'randn_tensor' from 'diffusers.utils' (/root/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/utils/__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m MAX_NUM_WORDS = \u001b[32m77\u001b[39m\n\u001b[32m      4\u001b[39m device = torch.device(\u001b[33m'\u001b[39m\u001b[33mcuda:0\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m torch.device(\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m stable = \u001b[43mAttendAndExcitePipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstabilityai/stable-diffusion-2-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m      6\u001b[39m tokenizer = stable.tokenizer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/pipelines/pipeline_utils.py:1022\u001b[39m, in \u001b[36mfrom_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1018\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1019\u001b[39m \u001b[33;03mConvert a numpy image or a batch of images to a PIL image.\u001b[39;00m\n\u001b[32m   1020\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m images.ndim == \u001b[32m3\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     images = images[\u001b[38;5;28;01mNone\u001b[39;00m, ...]\n\u001b[32m   1023\u001b[39m images = (images * \u001b[32m255\u001b[39m).round().astype(\u001b[33m\"\u001b[39m\u001b[33muint8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m images.shape[-\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m   1025\u001b[39m     \u001b[38;5;66;03m# special case for grayscale (single channel) images\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/pipelines/pipeline_loading_utils.py:830\u001b[39m, in \u001b[36mload_sub_model\u001b[39m\u001b[34m(library_name, class_name, importable_classes, pipelines, is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options, device_map, max_memory, offload_folder, offload_state_dict, model_variants, name, from_flax, variant, low_cpu_mem_usage, cached_folder, use_safetensors, dduf_entries, provider_options, quantization_config)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/schedulers/scheduling_utils.py:158\u001b[39m, in \u001b[36mfrom_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, subfolder, return_unused_kwargs, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[33;03m    Save a scheduler configuration object to the directory `save_directory`, so that it can be re-loaded using the\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[33;03m    [`~SchedulerMixin.from_pretrained`] class method.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    154\u001b[39m \u001b[33;03m            Directory where the configuration JSON file will be saved (will be created if it does not exist).\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    156\u001b[39m     \u001b[38;5;28mself\u001b[39m.save_config(save_directory=save_directory, push_to_hub=push_to_hub, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompatibles\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    160\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[33;03m    Returns all schedulers that are compatible with this scheduler\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m        `List[SchedulerMixin]`: List of compatible schedulers\u001b[39;00m\n\u001b[32m    165\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_compatibles()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/configuration_utils.py:251\u001b[39m, in \u001b[36mfrom_config\u001b[39m\u001b[34m(cls, config, return_unused_kwargs, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_config\u001b[39m(\n\u001b[32m    234\u001b[39m     \u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike], return_unused_kwargs=\u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs\n\u001b[32m    235\u001b[39m ) -> Tuple[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    236\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[33;03m    Instantiate a Python class from a config dictionary\u001b[39;00m\n\u001b[32m    238\u001b[39m \n\u001b[32m    239\u001b[39m \u001b[33;03m    Parameters:\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[33;03m        pretrained_model_name_or_path (`str` or `os.PathLike`, *optional*):\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[33;03m            Can be either:\u001b[39;00m\n\u001b[32m    242\u001b[39m \n\u001b[32m    243\u001b[39m \u001b[33;03m                - A string, the *model id* of a model repo on huggingface.co. Valid model ids should have an\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[33;03m                  organization name, like `google/ddpm-celebahq-256`.\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[33;03m                - A path to a *directory* containing model weights saved using [`~ConfigMixin.save_config`], e.g.,\u001b[39;00m\n\u001b[32m    246\u001b[39m \u001b[33;03m                  `./my_model_directory/`.\u001b[39;00m\n\u001b[32m    247\u001b[39m \n\u001b[32m    248\u001b[39m \u001b[33;03m        cache_dir (`Union[str, os.PathLike]`, *optional*):\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m            Path to a directory in which a downloaded pretrained model configuration should be cached if the\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[33;03m            standard cache should not be used.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[33;03m        force_download (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[33;03m            Whether or not to force the (re-)download of the model weights and configuration files, overriding the\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[33;03m            cached versions if they exist.\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[33;03m        resume_download (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[32m    255\u001b[39m \u001b[33;03m            Whether or not to delete incompletely received files. Will attempt to resume the download if such a\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[33;03m            file exists.\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[33;03m        proxies (`Dict[str, str]`, *optional*):\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m            A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128',\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[33;03m            'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[33;03m        output_loading_info(`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[33;03m            Whether or not to also return a dictionary containing missing keys, unexpected keys and error messages.\u001b[39;00m\n\u001b[32m    262\u001b[39m \u001b[33;03m        local_files_only(`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[32m    263\u001b[39m \u001b[33;03m            Whether or not to only look at local files (i.e., do not try to download the model).\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[33;03m        use_auth_token (`str` or *bool*, *optional*):\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[33;03m            The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[33;03m            when running `transformers-cli login` (stored in `~/.huggingface`).\u001b[39;00m\n\u001b[32m    267\u001b[39m \u001b[33;03m        revision (`str`, *optional*, defaults to `\"main\"`):\u001b[39;00m\n\u001b[32m    268\u001b[39m \u001b[33;03m            The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[33;03m            git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03m            identifier allowed by git.\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[33;03m        subfolder (`str`, *optional*, defaults to `\"\"`):\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[33;03m            In case the relevant files are located inside a subfolder of the model repo (either remote in\u001b[39;00m\n\u001b[32m    273\u001b[39m \u001b[33;03m            huggingface.co or downloaded locally), you can specify the folder name here.\u001b[39;00m\n\u001b[32m    274\u001b[39m \n\u001b[32m    275\u001b[39m \u001b[33;03m    <Tip>\u001b[39;00m\n\u001b[32m    276\u001b[39m \n\u001b[32m    277\u001b[39m \u001b[33;03m     It is required to be logged in (`huggingface-cli login`) when you want to use private or [gated\u001b[39;00m\n\u001b[32m    278\u001b[39m \u001b[33;03m     models](https://huggingface.co/docs/hub/models-gated#gated-models).\u001b[39;00m\n\u001b[32m    279\u001b[39m \n\u001b[32m    280\u001b[39m \u001b[33;03m    </Tip>\u001b[39;00m\n\u001b[32m    281\u001b[39m \n\u001b[32m    282\u001b[39m \u001b[33;03m    <Tip>\u001b[39;00m\n\u001b[32m    283\u001b[39m \n\u001b[32m    284\u001b[39m \u001b[33;03m    Activate the special [\"offline-mode\"](https://huggingface.co/transformers/installation.html#offline-mode) to\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03m    use this method in a firewalled environment.\u001b[39;00m\n\u001b[32m    286\u001b[39m \n\u001b[32m    287\u001b[39m \u001b[33;03m    </Tip>\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    289\u001b[39m     cache_dir = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcache_dir\u001b[39m\u001b[33m\"\u001b[39m, DIFFUSERS_CACHE)\n\u001b[32m    290\u001b[39m     force_download = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mforce_download\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/configuration_utils.py:493\u001b[39m, in \u001b[36mextract_init_dict\u001b[39m\u001b[34m(cls, config_dict, **kwargs)\u001b[39m\n\u001b[32m    486\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconfig\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    488\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    Returns the config of the class as a frozen dictionary\u001b[39;00m\n\u001b[32m    490\u001b[39m \n\u001b[32m    491\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    492\u001b[39m \u001b[33;03m        `Dict[str, Any]`: Config of the class.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._internal_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/schedulers/scheduling_utils.py:192\u001b[39m, in \u001b[36m_get_compatibles\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/utils/import_utils.py:874\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/utils/import_utils.py:873\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/utils/import_utils.py:885\u001b[39m, in \u001b[36m_get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to import diffusers.schedulers.scheduling_ddpm because of the following error (look up to see its traceback):\ncannot import name 'randn_tensor' from 'diffusers.utils' (/root/miniconda3/envs/tide/lib/python3.12/site-packages/diffusers/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "NUM_DIFFUSION_STEPS = 50\n",
    "GUIDANCE_SCALE = 7.5\n",
    "MAX_NUM_WORDS = 77\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "stable = AttendAndExcitePipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\").to(device)\n",
    "tokenizer = stable.tokenizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
